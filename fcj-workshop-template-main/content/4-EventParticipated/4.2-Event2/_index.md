---
title: "Event 2"
date: "2025-09-09"
weight: 1
chapter: false
pre: " <b> 4.2. </b> "
---


# Summary Report: “AI/ML/GenAI on AWS”

### Event Objectives

- Provide an overview of the AI/ML/GenAI ecosystem on AWS
- Guide participants through the full ML lifecycle using Amazon SageMaker
- Explain and demo Foundation Models on Amazon Bedrock
- Present Prompt Engineering, RAG, and Bedrock Agents techniques
- Build a GenAI chatbot through a live demo

### Agenda-based Highlights

#### 8:30 – 9:00 AM | Welcome & Introduction
**Main activities:**
- Participant check-in and networking
- Workshop learning objectives
- Ice-breaker activity
- Overview of the AI/ML landscape in Vietnam
**Key takeaway:**
Gained a clearer view of AI/ML trends in Vietnamese enterprises and how AWS supports digital transformation with GenAI and ML.

#### 9:00 – 10:30 AM | AWS AI/ML Services Overview
**Main content:**
- Introduction to Amazon SageMaker as an end-to-end ML platform
- Data preparation and labeling
- Model training, tuning, and deployment
- Integrated MLOps in SageMaker
- Live Demo: SageMaker Studio walkthrough
**Key takeaway:**
Understood the full ML development lifecycle on AWS, how to prepare data, monitor training/tuning/deployment, grasped real-world MLOps, and experienced SageMaker Studio and workflow hands-on.

#### 10:30 – 10:45 AM | Coffee Break
Short networking and discussion break with AWS experts and other participants.

#### 10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock
**Main content:**
- Foundation Models: Claude, Llama, Titan — comparison & selection guide
- Prompt Engineering: Techniques, Chain-of-Thought reasoning, Few-shot learning
- RAG (Retrieval-Augmented Generation): Architecture, Knowledge Base integration
- Bedrock Agents: Multi-step workflows, tool integrations
- Guardrails: Safety, content filtering
- Live Demo: Building a GenAI chatbot with Amazon Bedrock
**Key takeaway:**
Learned how to select the right Foundation Model, master prompt engineering (CoT, few-shot), build a complete RAG system, use Bedrock Agents for multi-step workflows, understand content safety standards and Guardrails, and follow the full GenAI chatbot creation process.

### Key Takeaways

- Comprehensive understanding of ML and GenAI on AWS
- Understood the differences and use cases for FM models (Claude/Llama/Titan)
- Applied Chain-of-Thought and Few-shot to improve output quality
- Learned to design prompts for complex pipelines
- Understood why RAG is needed in enterprise apps and how to connect Bedrock to Knowledge Base
- Learned to build agents with tool integration
- Hands-on experience with SageMaker Studio and end-to-end ML workflow
- Understood how to deploy enterprise AI chatbots using AWS standards

### Applying to Work

- Apply RAG to internal chatbots or document support systems
- Use SageMaker to train/fine-tune ML models
- Use Prompt Engineering to improve FM output quality
- Integrate Bedrock Agents to automate workflows
- Build GenAI demos for team/project

### Event Experience

Attending “AI/ML/GenAI on AWS” was an extremely valuable experience, deepening my understanding of how enterprises implement AI/ML and GenAI in practice.

#### Highlights
- Learning from AWS experts: Clear analysis of the AI/ML roadmap for Vietnamese enterprises, real-world demos of SageMaker and Bedrock.
- Hands-on demo sessions: Directly observed the train → tune → deploy process, Bedrock chatbot demo clarified the GenAI app building workflow.
- Networking & Discussions: Opportunities to discuss with AWS engineers and other participants, learn from real GenAI case studies.
- Lessons learned: GenAI is not just a model but a complete workflow (Prompt → RAG → Agents → Guardrails), SageMaker standardizes the ML lifecycle, and model selection is crucial for efficiency and cost.

#### Some event photos
![Event photo](/images/4-EventParticipated/event2-1.jpeg)
![Event photo](/images/4-EventParticipated/event2-2.jpeg)
![Event photo](/images/4-EventParticipated/event2-3.jpeg)
> Overall, the event not only provided technical knowledge but also helped me reshape my thinking about AI/ML application, system modernization, and more effective cross-team collaboration.
